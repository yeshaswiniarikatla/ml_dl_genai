{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b60cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4338bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m553467096/553467096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 0us/step\n",
      "[INFO]VGG16 model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "#step1:load pretrained vgg16 model\n",
    "model=VGG16(weights=\"imagenet\")\n",
    "print(\"[INFO]VGG16 model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494a7c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STEP] Loading image from:cat.jpg.jpg\n",
      "[debug] original array shape:(224, 224, 3)\n",
      "after expand_dims:(1, 224, 224, 3)\n",
      "preprocessing done\n"
     ]
    }
   ],
   "source": [
    "#step2: load and preprocess image\n",
    "img_path=\"cat.jpg.jpg\"\n",
    "print(f\"[STEP] Loading image from:{img_path}\")\n",
    "\n",
    "img= image.load_img(img_path,target_size=(224,224)) #it loads image into memory but it is image object.and it gives dimensions like it must in 224 heigth and 224 width size but not values it just gives size\n",
    "x=image.img_to_array(img) #it converts img_obj to numpy array(machine underatnds only numpy arrays(numbers)). and now it gives numbers(values) to pixels.(0,224,223) for one pixel as it is coloured and like that we have 224 rows 224 coloumns with one pixel into 3 channels(224*224*3).now machine do claculations on this numbers.\n",
    "print(f\"[debug] original array shape:{x.shape}\")\n",
    "\n",
    "x= np.expand_dims(x,axis=0) #keras always takes images as batches ((224,224,3)->one image,no batch),((1,224,224,3)->batch of 1 image),((60000,28 28,1)->60k images(batch dimension),28*28 image size, 1channel i.e gray),((1,224,224,3)-> 1 image(batch dimension),224*224 size,3 channels)\n",
    "#if you dont tell batch dimension it thinks we are giving just a raw image ,by adding batch dimension we tellig that the batch has 1 image,but still its a batch.\n",
    "# axis=0 means we are giving that dimension at 0th index.axis=0 means dimension,axis=1 means 224 rows like that\n",
    "print(f\"after expand_dims:{x.shape}\")\n",
    "\n",
    "x= preprocess_input(x)\n",
    "print(\"preprocessing done\") #it normalizes the data.basically we give float32/255 when we train our own model\n",
    "#but here to match the format of vgg preprocessing we give function like this.so now our own image is normalized\n",
    "#in the same format as how their dataset is preprocessed.if we doesnt preprocess like that model doesnt understand \n",
    "#our data because it trained like that format and gives low accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5efbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prediction\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "prediction_shape: {(1, 1000)}\n"
     ]
    }
   ],
   "source": [
    "#step3:run prediction with VGG16\n",
    "print(\"running prediction\")\n",
    "preds=model.predict(x) # it gives predictions of 1000 classes using softmax(it gives just probablities for \n",
    "# all thousand classes without their label names)it take image and apply filters,relu,pooling etc..\n",
    "print(\"prediction_shape:\",{preds.shape})# (1,1000) means 1 image and 1000 classes i,e 1000 predictions  for one image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc7e59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top three predictions are:\n",
      "1.Egyptian_cat(0.46)\n",
      "2.tabby(0.25)\n",
      "3.tiger_cat(0.04)\n"
     ]
    }
   ],
   "source": [
    "#decode top 3 predictions\n",
    "print(\"top three predictions are:\")\n",
    "for i, (imagenet_id,label,score) in enumerate(decode_predictions(preds,top=3)[0]): #predict function only gives probababilities without labels.so we dont understand what is that image.\n",
    "    print(f\"{i+1}.{label}({score:.2f})\") # so when we use decode_predictions it map index values with label names like\n",
    "    #[(imagenet_id,label,prob)] as we give top 3 it gives top 3 highest proababilities with label name.\n",
    "    #and[0] means decode_predictions(preds,top=3) gives list of lists.outer list= one list per image i.e how many sublists(list in a list) are there that many images info it gives as we have only one img it\n",
    "    #gives only one sublist so to access first image info we give [0] \n",
    "    #[[('n02124075', 'egyptian cat',0.46),('no2123045','tabby',0.32),(n0213159, tigercat,0.15)]]#sub list is for image and tuple is for img info.. and decode_predictions[0] picks only inner list. as we use [0] outer list is gone and picks the element at 0th index.so we can directly iterate over tuples.\n",
    "    # enumerate gives index value and as well as item names so we use enumerate to get index no and their value\n",
    "    # i takes index number and(imagenet_id,label,prob)takes tuple info i.e at 0 th index 1st highest probbaility info, at 1st index second highest prob info like that\n",
    "    # to print nicely we give i+1 which starts numbering from 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
